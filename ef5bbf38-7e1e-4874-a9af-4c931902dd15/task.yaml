prompt: |
  Supply Chain Route Anomaly Detection with Multi-Constraint Selection

  Files (JSON, read-only):
  /workdir/data/routes.json
  /workdir/data/shipments.json
  /workdir/data/weather_events.json
  /workdir/data/warehouse_capacity.json

  Reference date: 2025-10-30 (use this as "today" for all date calculations)

  ## PART 1: Anomaly Score Calculation (unchanged from original)

  Eligibility (route-level):
  • route.status == "active"
  • route.monthly_volume ≥ 100
  • at least 20 shipments in the last 60 days (shipments with date within 60 days before 2025-10-30)

  Anomaly components (compute exactly):
  1) delay_volatility_score:
     • For each shipment on the route in last 60 days, compute delay_hours = actual_delivery_time - expected_delivery_time (in hours).
       - Parse timestamps as ISO format and compute difference.
       - If delay_hours < 0, treat as 0 (early deliveries don't count as anomalies).
     • Compute standard deviation of delay_hours across all shipments.
       - Use sample standard deviation: sqrt(Σ(x - mean)² / (n-1)) where n = number of shipments.
       - If n < 2, std_dev = 0.0.
     • delay_volatility_score = min(1.0, std_dev / 24.0) (normalize by 24 hours).

  2) cost_inflation_score:
     • For each route, calculate cost_per_km for each shipment = shipment.cost / route.distance_km.
     • Compute median cost_per_km for the route across all shipments in last 60 days.
     • Compute 75th percentile cost_per_km using this EXACT method:
       - Sort cost_per_km values in ascending order: sorted_values = sorted(cost_per_km_list)
       - Calculate index: p75_index = int(len(sorted_values) * 0.75)
       - Handle boundary case: if p75_index >= len(sorted_values), set p75_index = len(sorted_values) - 1
       - Percentile value: percentile_75 = sorted_values[p75_index]
       - Do NOT use numpy.percentile(), scipy.stats, or other interpolation methods
     • cost_inflation_ratio = (percentile_75 - median) / median if median > 0, else 0.0.
     • cost_inflation_score = min(1.0, cost_inflation_ratio * 2.0).

  3) weather_impact_correlation:
     • Count severe_weather_days = number of unique dates where route experienced severe weather (weather_events.severity == "severe" or "extreme").
       - Match weather_events.route_id with route and filter by last 60 days.
     • Count delayed_shipment_days = number of unique dates where at least one shipment on route had delay_hours > 6.
     • If severe_weather_days > 0:
         expected_delayed_days = severe_weather_days * 0.7 (we expect 70% correlation).
         weather_impact_correlation = max(0, (delayed_shipment_days - expected_delayed_days) / severe_weather_days).
       Else weather_impact_correlation = 0.0.
     • Cap to [0, 1].

  4) capacity_utilization_penalty:
     • For each shipment, compute utilization = shipment.weight_kg / warehouse_capacity.max_weight_kg for the destination warehouse.
       - Match shipment.destination_warehouse_id with warehouse_capacity.warehouse_id.
     • Count overutilization_shipments = shipments where utilization > 0.85.
     • total_shipments = all route shipments in last 60 days.
     • capacity_utilization_penalty = min(1.0, overutilization_shipments / total_shipments) if total_shipments > 0, else 0.0.

  Final anomaly score:
  anomaly_score = 3.0*delay_volatility_score + 2.5*cost_inflation_score + 4.0*weather_impact_correlation + 3.5*capacity_utilization_penalty

  ## PART 2: Multi-Constraint Selection (NEW - CRITICAL)

  You CANNOT simply take the top 8 routes by anomaly_score. You must find a valid set of 8 routes that satisfies ALL constraints:

  CONSTRAINT 1: Regional Diversity (MANDATORY)
  Define regions by destination_city:
  - West Region: Los Angeles, Phoenix, Salt Lake City, San Francisco, San Diego
  - East Region: Miami, New York, Boston, Washington DC, Tampa
  - Central Region: Dallas, Chicago, Omaha, Cleveland, Memphis, San Antonio, Atlanta, Nashville, Charlotte, Kansas City, Minneapolis, Houston, New Orleans, Pittsburgh, Orlando, Austin
  
  REQUIREMENT: Selected 8 routes must include:
  • At least 2 routes with destination in West Region
  • At least 2 routes with destination in East Region  
  • At least 2 routes with destination in Central Region
  • Remaining 2 routes can be from any region

  CONSTRAINT 2: Volume Coverage (MANDATORY)
  REQUIREMENT: Sum of monthly_volume for all 8 selected routes must be ≥ 2,800

  CONSTRAINT 3: Warehouse Distribution (MANDATORY)
  REQUIREMENT: No more than 3 selected routes can share the same destination_warehouse_id

  CONSTRAINT 4: Geographic Diversity (MANDATORY)
  REQUIREMENT: The 8 selected routes must deliver to at least 6 different destination cities

  Selection algorithm:
  1. Compute anomaly_score for all eligible routes
  2. Find ALL valid combinations of 8 routes that satisfy constraints 1-4
     - There are C(n,8) possible combinations where n = number of eligible routes
     - Filter to only combinations that pass all 4 constraints
  3. Among valid combinations, select the one with the HIGHEST sum of anomaly_scores
  4. If multiple combinations have identical total scores, choose the one with highest total distance_km (sum of distance_km for the 8 routes)

  CRITICAL: Most agents will fail by simply taking top 8 routes without checking constraints. You MUST validate constraints.

  Output validation checks (your solution must pass these):
  ✓ check_regional_diversity(): At least 2 West, 2 East, 2 Central
  ✓ check_volume_coverage(): Sum of monthly_volume ≥ 2,800
  ✓ check_warehouse_distribution(): No warehouse appears >3 times
  ✓ check_geographic_diversity(): At least 6 unique destination cities
  ✓ check_optimality(): No other valid combination has higher total anomaly score

  Output (CSV → /workdir/sol.csv):
  
  FORMAT: Standard CSV with header row + 8 data rows ONLY. No additional lines.
  
  Header (exact format required):
  route_id,route_name,origin_city,destination_city,destination_region,monthly_volume,destination_warehouse_id,distance_km,delay_volatility_score,cost_inflation_score,weather_impact_correlation,capacity_utilization_penalty,anomaly_score,rank

  Data rows: Exactly 8 rows with the selected routes

  New columns explained:
  • destination_region: "West", "East", or "Central" (based on destination_city)
  • monthly_volume: from routes.json (integer, no decimals)
  • destination_warehouse_id: from shipments.json (string)
  • distance_km: from routes.json (integer, no decimals)

  Formatting (CRITICAL - must match exactly):
  • All decimal scores MUST use Python format string f"{value:.3f}" to ensure exactly 3 decimal places
  • This means trailing zeros MUST be preserved:
    - Write "1.000" not "1.0"
    - Write "0.500" not "0.5"
  • Columns requiring f"{x:.3f}" formatting:
    - delay_volatility_score, cost_inflation_score, weather_impact_correlation,
      capacity_utilization_penalty, anomaly_score
  • Integer columns (no decimals): monthly_volume, distance_km
  • String columns: route_id, route_name, origin_city, destination_city, 
                   destination_region, destination_warehouse_id
  • rank: integer 1 through 8 (sorted by anomaly_score DESC within the valid set)
  • Exactly 8 data rows. No extra columns. No index column.
  • NO validation summary, NO comment lines, NO additional rows - just header + 8 data rows

  IMPORTANT: The CSV must contain ONLY:
  - Line 1: Header row
  - Lines 2-9: Exactly 8 data rows
  - Total: 9 lines
  - Do NOT add validation comments, summary lines, or any other content

metadata:
  difficulty: expert
  category: "data-science"
  tags: ["supply-chain","anomaly-detection","constraint-satisfaction","optimization","logistics"]
  references: ["combinatorial-optimization"]
time_limit: 1200
memory_limit: 2048
max_agent_timeout_sec: 900
expert_time_estimate_min: 90
junior_time_estimate_min: 240