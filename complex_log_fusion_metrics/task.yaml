prompt: |
  You are inside a Linux container without internet.
  Goal: Produce /workdir/sol.csv with the exact header and rows below:
    Columns: user_id,p95_ms,error_rate
    - user_id: string (sorted ascending)
    - p95_ms: integer (95th percentile latency in milliseconds; round half up to nearest int)
    - error_rate: decimal in [0,1] with exactly 4 digits after the decimal (round half up)

  Input logs are under /workdir/data/logs/ and may be:
    - CSV (possibly .bz2)
    - JSONL (possibly .gz)

  CSV schema (header present):
    ts,request_id,user_id,path,status,latency_ms
  JSONL schema (one JSON object per line, same keys as CSV):
    {"ts": "...", "request_id": "...", "user_id": "...", "path": "...", "status": 200, "latency_ms": 123}

  Comments & malformed lines:
    - Lines beginning with '#' or '//' are comments and MUST be ignored.
    - Malformed lines MUST be skipped silently (do not raise/print errors).

  Processing requirements:
    1) Consider only requests where path == "/api/v2/order".
    2) Deduplicate across files by request_id (keep exactly one record per request_id).
    3) Normalize all timestamps to UTC, then filter the UTC window (inclusive):
         start = 2023-03-26T01:00:00Z
         end   = 2023-03-26T02:30:00Z
    4) Compute per-user metrics:
         - p95_ms: 95th percentile of latency_ms; round half up to integer.
         - error_rate: (# with status >= 500) / (total rows for the user),
           rounded half up to 4 decimals (e.g., 0.0123).
    5) Write exactly one CSV at /workdir/sol.csv with the header
       user_id,p95_ms,error_rate and rows sorted by user_id ascending.

  Notes:
    - Compressed files use standard gzip (.gz) or bzip2 (.bz2).
    - Do NOT hardcode answers. Your solution must work for any dataset in this format.
    - Do NOT print to stdout; grading only inspects /workdir/sol.csv.

metadata:
  difficulty: hard
  category: short
  tags: [devops, data-engineering, log-parsing, unix, analytics]
  references: ["N/A"]

time_limit: 300              # seconds (5 minutes is typical for hard tasks)
memory_limit: 1024           # MB
max_agent_timeout_sec: 600   # hard cap for agent execution (10 minutes)
expert_time_estimate_min: 30 # expected time for an expert
junior_time_estimate_min: 120 # expected time for a junior engineer
