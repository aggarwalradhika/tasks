prompt: |
  You are inside a Linux container without internet.
  Goal: Produce /workdir/results.json with statistical analysis of A/B test experiments.

  Input data is under /workdir/data/experiments/ and may contain:
    - CSV files (possibly .gz compressed)
    - JSONL files (possibly .bz2 compressed)
    - Nested directories (must search recursively)

  CSV schema (header present):
    experiment_id,user_id,variant,metric_type,metric_value,timestamp,country,device
  
  JSONL schema (one JSON object per line, same keys as CSV):
    {"experiment_id": "exp_001", "user_id": "u123", "variant": "control", 
     "metric_type": "conversion", "metric_value": 1, "timestamp": "2024-01-15T10:30:00Z",
     "country": "US", "device": "mobile"}

  Comments & malformed lines:
    - Lines beginning with '#' or '//' are comments and MUST be ignored.
    - Malformed lines MUST be skipped silently (do not raise/print errors).
    - CSV cells may contain inline comments after '#' - strip these.

  Processing requirements:
    1) Only analyze variants named "control" and "treatment" (ignore others).
    2) Deduplicate by (experiment_id, user_id, variant, metric_type) - keep the LAST occurrence (by timestamp).
    3) For each experiment_id, analyze ALL metric_types present.
    4) Experiments must have BOTH control and treatment data to be valid.
    5) Filter to only include data from timestamp range: 
       start = 2024-01-15T00:00:00Z, end = 2024-01-31T23:59:59Z (inclusive)
    6) Perform SEGMENTED analysis: analyze separately by country AND device.
       - Valid countries: US, UK, CA, DE, FR (ignore others)
       - Valid devices: mobile, desktop, tablet (ignore others)

  Statistical Analysis (per experiment, per metric_type, per country, per device):
    
    For BINARY metrics (metric_value in {0, 1}):
      - Calculate conversion rate for each variant: sum(metric_value) / count(users)
      - Perform two-proportion z-test (two-tailed)
      - Calculate: z_statistic, p_value, lift (% change from control to treatment)
      - Calculate confidence interval (95%) for the difference in proportions (treatment - control)
        using standard normal approximation: diff Â± 1.96 * SE where
        SE = sqrt(p1*(1-p1)/n1 + p2*(1-p2)/n2)
    
    For CONTINUOUS metrics (any numeric values):
      - Calculate mean for each variant: sum(metric_value) / count(users)
      - Perform Welch's t-test (two-tailed, unequal variances)
      - Calculate: t_statistic, p_value, lift (% change from control to treatment)
      - Calculate confidence interval (95%) for the difference in means
      - Calculate Cohen's d effect size: (mean_treatment - mean_control) / pooled_std
    
    Metric type detection:
      - If ALL metric_values for a metric_type are in {0, 1, 0.0, 1.0}: BINARY
      - Otherwise: CONTINUOUS

  Sample Size Filtering:
    - Only include segments with at least 30 samples in BOTH control and treatment
    - Segments not meeting this threshold should be excluded from results

  Multiple Testing Correction:
    - Apply Benjamini-Hochberg (FDR) correction instead of Bonferroni
    - Control false discovery rate at q = 0.05
    - Sort all p-values across all tests, apply BH procedure
    - Mark test as "significant": true if passes FDR threshold, else false

  Power Analysis:
    - For each test, calculate statistical power (1 - beta) assuming:
      - alpha = 0.05 (before correction)
      - observed effect size
      - actual sample sizes
    - Round power to 4 decimal places

  Rounding & Precision:
    - Conversion rates / means: 6 decimal places
    - Lift: 4 decimal places (as percentage, e.g., 15.2500 for 15.25%)
    - p_value: 6 decimal places
    - z_statistic / t_statistic: 4 decimal places
    - confidence intervals: 4 decimal places (as raw difference, not percentage)
    - effect_size (Cohen's d): 4 decimal places
    - power: 4 decimal places
    - fdr_threshold: 6 decimal places

  Output format (/workdir/results.json):
    {
      "total_tests": <integer>,
      "fdr_threshold": <float with 6 decimals>,
      "experiments": [
        {
          "experiment_id": "exp_001",
          "segments": [
            {
              "country": "US",
              "device": "mobile",
              "metrics": [
                {
                  "metric_type": "conversion",
                  "metric_kind": "binary",
                  "control_n": 45,
                  "treatment_n": 48,
                  "control_value": 0.123456,
                  "treatment_value": 0.145678,
                  "lift_percent": 18.0500,
                  "confidence_interval": [-0.0523, 0.0987],
                  "test_statistic": 2.3456,
                  "p_value": 0.019234,
                  "power": 0.6234,
                  "significant": true
                },
                {
                  "metric_type": "revenue",
                  "metric_kind": "continuous",
                  "control_n": 45,
                  "treatment_n": 48,
                  "control_value": 45.678900,
                  "treatment_value": 52.341200,
                  "lift_percent": 14.5800,
                  "confidence_interval": [2.1200, 11.2050],
                  "test_statistic": 1.8765,
                  "p_value": 0.061234,
                  "effect_size": 0.4523,
                  "power": 0.4821,
                  "significant": false
                }
              ]
            }
          ]
        }
      ]
    }

  Sort order:
    - experiments: sorted by experiment_id (ascending)
    - segments within each experiment: sorted by country then device (ascending)
    - metrics within each segment: sorted by metric_type (ascending)

  Notes:
    - Use scipy.stats for statistical tests and power analysis
    - For binary z-test, use pooled proportion for standard error in the test statistic
    - For confidence intervals on binary metrics, use unpooled standard error
    - Lift = ((treatment_value - control_value) / control_value) * 100
    - Cohen's d uses pooled standard deviation: sqrt(((n1-1)*s1^2 + (n2-1)*s2^2) / (n1+n2-2))
    - Power calculation should account for actual sample sizes and observed effect
    - Do NOT hardcode answers. Your solution must work for any dataset.
    - Do NOT print to stdout; grading only inspects /workdir/results.json.
    - Search ALL subdirectories recursively for data files.

metadata:
  difficulty: hard
  category: data-science
  tags: [data-science, statistics, hypothesis-testing, a-b-testing, analytics, segmentation, fdr]
  references: "N/A"
  time_limit: 600
  memory_limit: 2048
  max_agent_timeout_sec: 900
  expert_time_estimate_min: 60
  junior_time_estimate_min: 180